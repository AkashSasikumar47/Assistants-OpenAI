{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuHyMepBklgs3qy5iIcRCR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "JeCV5opqUoAA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "xHAJVPS9U9ji"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the documents\n",
        "loader = CSVLoader(file_path='stock20.csv')"
      ],
      "metadata": {
        "id": "w7ijOQR-VG_q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "uNkj34ksYs--"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "\n",
        "index_creator = VectorstoreIndexCreator(embedding=embeddings)\n",
        "docsearch = index_creator.from_loaders([loader])"
      ],
      "metadata": {
        "id": "lFauWY7pY0qS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a question-answering chain using the index\n",
        "chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzXqPyGwbRnK",
        "outputId": "113eba79-dff8-42d8-dc03-4ac193d3a90b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-95c975763e5b>:2: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass a query to the chain\n",
        "query = \"What is the highest GP?\"\n",
        "response = chain({\"question\": query})"
      ],
      "metadata": {
        "id": "7KU2HlVwbXTB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOUew3r_baix",
        "outputId": "0c6b9068-2818-49d6-96a9-205420255408"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The highest GP is 172.240005493164.\n"
          ]
        }
      ]
    }
  ]
}